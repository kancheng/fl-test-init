{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Qiuyan918/Unet_Implementation_PyTorch/blob/master/Unet_Implementation_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJJcl5Day-aS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3BehnPezvFY"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPEAHcCDzzQ6"
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "pad_left = 27\n",
    "pad_right = 27\n",
    "fine_size = 202\n",
    "batch_size = 18\n",
    "# epoch = 300\n",
    "epoch = 30\n",
    "snapshot = 6 \n",
    "max_lr = 0.012 \n",
    "min_lr = 0.001 \n",
    "momentum = 0.9 \n",
    "weight_decay = 1e-4 \n",
    "n_fold = 5\n",
    "device = torch.device('cuda')\n",
    "save_weight = 'weights/'\n",
    "if not os.path.isdir(save_weight):\n",
    "  os.mkdir(save_weight)\n",
    "weight_name = 'model_' + str(fine_size+pad_left+pad_right) + '_res18' \n",
    "\n",
    "train_image_dir = 'tgs-salt-identification-challenge/train/images'\n",
    "train_mask_dir = 'tgs-salt-identification-challenge/train/masks'\n",
    "test_image_dir = 'tgs-salt-identification-challenge/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KY7UTuce1d0T"
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v90Ul61N0hKF"
   },
   "outputs": [],
   "source": [
    "depths = pd.read_csv('tgs-salt-identification-challenge/depths.csv')\n",
    "depths.sort_values('z', inplace=True)\n",
    "depths.drop('z', axis=1, inplace=True)\n",
    "depths['fold'] = (list(range(0,5)) * depths.shape[0])[:depths.shape[0]]\n",
    "\n",
    "train_df = pd.read_csv('tgs-salt-identification-challenge/train.csv')\n",
    "train_df = train_df.merge(depths)\n",
    "dist = []\n",
    "for id in train_df.id.values:\n",
    "  img = cv2.imread(f'tgs-salt-identification-challenge/train/images/{id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "  dist.append(np.unique(img).shape[0])\n",
    "train_df['unique_pixels'] = dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UI0u3k-l564p"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MDKVsgDXZ5g"
   },
   "outputs": [],
   "source": [
    "def trainImageFetch(images_id):\n",
    "  image_train = np.zeros((images_id.shape[0], 101, 101), dtype=np.float32)\n",
    "  mask_train = np.zeros((images_id.shape[0], 101, 101), dtype=np.float32)\n",
    "\n",
    "  for idx, image_id in tqdm(enumerate(images_id), total=images_id.shape[0]):\n",
    "    image_path = os.path.join(train_image_dir, image_id+'.png')\n",
    "    mask_path = os.path.join(train_mask_dir, image_id+'.png')\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "\n",
    "    image_train[idx] = image\n",
    "    mask_train[idx] = mask\n",
    "  \n",
    "  return image_train, mask_train\n",
    "\n",
    "def testImageFetch(test_id):\n",
    "  image_test = np.zeros((len(test_id), 101, 101), dtype=np.float32)\n",
    "\n",
    "  for idx, image_id in tqdm(enumerate(test_id), total=len(test_id)):\n",
    "    image_path = os.path.join(test_image_dir, image_id+'.png')\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "    image_test[idx] = image\n",
    "\n",
    "  return image_test\n",
    "\n",
    "def do_resize2(image, mask, H, W):\n",
    "  image = cv2.resize(image, dsize=(W,H))\n",
    "  mask = cv2.resize(mask, dsize=(W,H))\n",
    "  return image, mask\n",
    "\n",
    "def do_center_pad(image, pad_left, pad_right):\n",
    "  return np.pad(image, (pad_left, pad_right), 'edge')\n",
    "\n",
    "def do_center_pad2(image, mask, pad_left, pad_right):\n",
    "  image = do_center_pad(image, pad_left, pad_right)\n",
    "  mask = do_center_pad(mask, pad_left, pad_right)\n",
    "  return image, mask\n",
    "\n",
    "class SaltDataset(Dataset):\n",
    "  def __init__(self, image_list, mode, mask_list=None, fine_size=202, pad_left=0, pad_right=0):\n",
    "    self.imagelist = image_list\n",
    "    self.mode = mode\n",
    "    self.masklist = mask_list\n",
    "    self.fine_size = fine_size\n",
    "    self.pad_left = pad_left\n",
    "    self.pad_right = pad_right\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imagelist)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = deepcopy(self.imagelist[idx])\n",
    "\n",
    "    if self.mode == 'train':\n",
    "      mask = deepcopy(self.masklist[idx])\n",
    "      label = np.where(mask.sum() == 0, 1.0, 0.0).astype(np.float32)\n",
    "\n",
    "      if self.fine_size != image.shape[0]:\n",
    "        image, mask = do_resize2(image, mask, self.fine_size, self.fine_size)\n",
    "\n",
    "      if self.pad_left != 0:\n",
    "        image, mask = do_center_pad2(image, mask, self.pad_left, self.pad_right)\n",
    "\n",
    "      image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "      mask = mask.reshape(1, mask.shape[0], mask.shape[1])    \n",
    "\n",
    "      return image, mask, label\n",
    "\n",
    "    elif self.mode == 'val':\n",
    "      mask = deepcopy(self.masklist[idx])\n",
    "\n",
    "      if self.fine_size != image.shape[0]:\n",
    "        image, mask = do_resize2(image, mask, self.fine_size, self.fine_size)\n",
    "\n",
    "      if self.pad_left != 0:\n",
    "        image = do_center_pad(image, self.pad_left, self.pad_right)\n",
    "\n",
    "      image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "      mask = mask.reshape(1, mask.shape[0], mask.shape[1])  \n",
    "\n",
    "      return image, mask\n",
    "\n",
    "    elif self.mode == 'test':\n",
    "      if self.fine_size != image.shape[0]:\n",
    "        image = cv2.resize(image, dsize=(self.fine_size, self.fine_size))\n",
    "\n",
    "      if self.pad_left != 0:\n",
    "        image = do_center_pad(image, self.pad_left, self.pad_right)\n",
    "\n",
    "      image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "\n",
    "      return image     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5gnjD4X69f6"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZz39glnTum1"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, in_channels, middle_channels, out_channels):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    self.conv_relu = nn.Sequential(\n",
    "        nn.Conv2d(middle_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "  def forward(self, x1, x2):\n",
    "    x1 = self.up(x1)\n",
    "    x1 = torch.cat((x1, x2), dim=1)\n",
    "    x1 = self.conv_relu(x1)\n",
    "    return x1\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = torchvision.models.resnet18(True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            self.base_layers[1],\n",
    "            self.base_layers[2])\n",
    "        self.layer2 = nn.Sequential(*self.base_layers[3:5])\n",
    "        self.layer3 = self.base_layers[5]\n",
    "        self.layer4 = self.base_layers[6]\n",
    "        self.layer5 = self.base_layers[7]\n",
    "        self.decode4 = Decoder(512, 256+256, 256)\n",
    "        self.decode3 = Decoder(256, 256+128, 256)\n",
    "        self.decode2 = Decoder(256, 128+64, 128)\n",
    "        self.decode1 = Decoder(128, 64+64, 64)\n",
    "        self.decode0 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False)\n",
    "            )\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        e1 = self.layer1(input) # 64,128,128\n",
    "        e2 = self.layer2(e1) # 64,64,64\n",
    "        e3 = self.layer3(e2) # 128,32,32\n",
    "        e4 = self.layer4(e3) # 256,16,16\n",
    "        f = self.layer5(e4) # 512,8,8\n",
    "        d4 = self.decode4(f, e4) # 256,16,16\n",
    "        d3 = self.decode3(d4, e3) # 256,32,32\n",
    "        d2 = self.decode2(d3, e2) # 128,64,64\n",
    "        d1 = self.decode1(d2, e1) # 64,128,128\n",
    "        d0 = self.decode0(d1) # 64,256,256\n",
    "        out = self.conv_last(d0) # 1,256,256\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YJji98EGsZU"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OVx5-R6hMKc"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(train_data)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for inputs, masks, labels in train_loader:\n",
    "    inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(inputs)\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(1), masks.squeeze(1))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "  epoch_loss = running_loss / data_size\n",
    "  return epoch_loss\n",
    "\n",
    "def test(test_loader, model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(test_loader)\n",
    "  predicts = []\n",
    "  truths = []\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  for inputs, masks in test_loader:\n",
    "    inputs, masks = inputs.to(device), masks.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "      outputs = model(inputs)\n",
    "      outputs = outputs[:, :, pad_left:pad_left + fine_size, pad_left:pad_left + fine_size].contiguous()\n",
    "      loss = nn.BCEWithLogitsLoss()(outputs.squeeze(1), masks.squeeze(1))\n",
    "\n",
    "    predicts.append(torch.sigmoid(outputs).detach().cpu().numpy()) \n",
    "    truths.append(masks.detach().cpu().numpy())\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "  predicts = np.concatenate(predicts).squeeze()\n",
    "  truths = np.concatenate(truths).squeeze()\n",
    "  precision, _, _ = do_kaggle_metric(predicts, truths, 0.5)\n",
    "  precision = precision.mean()\n",
    "  epoch_loss = running_loss / data_size\n",
    "  return epoch_loss, precision\n",
    "\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KecZvuwl5Oey"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GHbyq7iK3iRK",
    "outputId": "b80547f2-d53f-43d9-950e-5b2c2da975d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kan/anaconda3/envs/unet-init/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/kan/anaconda3/envs/unet-init/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode4): Decoder(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_relu): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode3): Decoder(\n",
       "    (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_relu): Sequential(\n",
       "      (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode2): Decoder(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_relu): Sequential(\n",
       "      (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode1): Decoder(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_relu): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode0): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_id = train_df['id'].values\n",
    "fold = []\n",
    "for i in range(5):\n",
    "  fold.append(train_df.loc[train_df['fold']==i, 'id'].values)\n",
    "\n",
    "salt = UNet(1)\n",
    "salt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kaggle_metric(predict,truth, threshold=0.5):\n",
    "\n",
    "    N = len(predict)\n",
    "    predict = predict.reshape(N,-1)\n",
    "    truth   = truth.reshape(N,-1)\n",
    "\n",
    "    predict = predict>threshold\n",
    "    truth   = truth>0.5\n",
    "    intersection = truth & predict\n",
    "    union        = truth | predict\n",
    "    iou = intersection.sum(1)/(union.sum(1)+1e-8)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    result = []\n",
    "    precision = []\n",
    "    is_empty_truth   = (truth.sum(1)==0)\n",
    "    is_empty_predict = (predict.sum(1)==0)\n",
    "\n",
    "    threshold = np.array([0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95])\n",
    "    for t in threshold:\n",
    "        p = iou>=t\n",
    "\n",
    "        tp  = (~is_empty_truth)  & (~is_empty_predict) & (iou> t)\n",
    "        fp  = (~is_empty_truth)  & (~is_empty_predict) & (iou<=t)\n",
    "        fn  = (~is_empty_truth)  & ( is_empty_predict)\n",
    "        fp_empty = ( is_empty_truth)  & (~is_empty_predict)\n",
    "        tn_empty = ( is_empty_truth)  & ( is_empty_predict)\n",
    "\n",
    "        p = (tp + tn_empty) / (tp + tn_empty + fp + fp_empty + fn)\n",
    "\n",
    "        result.append( np.column_stack((tp,fp,fn,tn_empty,fp_empty)) )\n",
    "        precision.append(p)\n",
    "\n",
    "    result = np.array(result).transpose(1,2,0)\n",
    "    precision = np.column_stack(precision)\n",
    "    precision = precision.mean(1)\n",
    "\n",
    "    return precision, result, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "09E37d074u2K",
    "outputId": "7927cb6e-7845-4f63-da0b-c07385fec9f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3190/3190 [00:00<00:00, 5043.81it/s]\n",
      "100%|███████████████████████████████████████| 810/810 [00:00<00:00, 5026.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 0.559 val_loss: 9.464 val_accuracy: 0.385\n",
      "epoch: 2 train_loss: 0.473 val_loss: 8.612 val_accuracy: 0.388\n",
      "epoch: 3 train_loss: 0.433 val_loss: 6.931 val_accuracy: 0.282\n",
      "epoch: 4 train_loss: 0.393 val_loss: 11.198 val_accuracy: 0.379\n",
      "epoch: 5 train_loss: 0.382 val_loss: 6.914 val_accuracy: 0.425\n",
      "epoch: 6 train_loss: 0.398 val_loss: 6.682 val_accuracy: 0.250\n",
      "epoch: 7 train_loss: 0.380 val_loss: 6.606 val_accuracy: 0.384\n",
      "epoch: 8 train_loss: 0.366 val_loss: 8.513 val_accuracy: 0.271\n",
      "epoch: 9 train_loss: 0.356 val_loss: 6.042 val_accuracy: 0.440\n",
      "epoch: 10 train_loss: 0.344 val_loss: 5.686 val_accuracy: 0.436\n",
      "epoch: 11 train_loss: 0.362 val_loss: 11.879 val_accuracy: 0.405\n",
      "epoch: 12 train_loss: 0.350 val_loss: 7.064 val_accuracy: 0.431\n",
      "epoch: 13 train_loss: 0.317 val_loss: 5.361 val_accuracy: 0.516\n",
      "epoch: 14 train_loss: 0.275 val_loss: 4.510 val_accuracy: 0.513\n",
      "epoch: 15 train_loss: 0.239 val_loss: 3.599 val_accuracy: 0.625\n",
      "epoch: 16 train_loss: 0.253 val_loss: 6.212 val_accuracy: 0.538\n",
      "epoch: 17 train_loss: 0.215 val_loss: 3.176 val_accuracy: 0.660\n",
      "epoch: 18 train_loss: 0.178 val_loss: 3.154 val_accuracy: 0.683\n",
      "epoch: 19 train_loss: 0.148 val_loss: 3.033 val_accuracy: 0.710\n",
      "epoch: 20 train_loss: 0.123 val_loss: 2.876 val_accuracy: 0.686\n",
      "epoch: 21 train_loss: 0.169 val_loss: 3.421 val_accuracy: 0.685\n",
      "epoch: 22 train_loss: 0.147 val_loss: 4.032 val_accuracy: 0.614\n",
      "epoch: 23 train_loss: 0.127 val_loss: 3.369 val_accuracy: 0.724\n",
      "epoch: 24 train_loss: 0.088 val_loss: 3.233 val_accuracy: 0.736\n",
      "epoch: 25 train_loss: 0.067 val_loss: 3.227 val_accuracy: 0.722\n",
      "epoch: 26 train_loss: 0.109 val_loss: 3.704 val_accuracy: 0.671\n",
      "epoch: 27 train_loss: 0.104 val_loss: 3.412 val_accuracy: 0.724\n",
      "epoch: 28 train_loss: 0.071 val_loss: 3.909 val_accuracy: 0.722\n",
      "epoch: 29 train_loss: 0.052 val_loss: 3.646 val_accuracy: 0.736\n",
      "epoch: 30 train_loss: 0.045 val_loss: 3.676 val_accuracy: 0.734\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  # Setup optimizer\n",
    "  scheduler_step = epoch // snapshot\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # Load data\n",
    "  train_id = np.setdiff1d(all_id, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "\n",
    "  X_train, y_train = trainImageFetch(train_id)\n",
    "  X_val, y_val = trainImageFetch(val_id)\n",
    "\n",
    "  train_data = SaltDataset(X_train, 'train', y_train, pad_left=27, pad_right=27)\n",
    "  val_data = SaltDataset(X_val, 'val', y_val, pad_left=27, pad_right=27)\n",
    "\n",
    "  train_loader = DataLoader(train_data,\n",
    "                            shuffle=RandomSampler(train_data), \n",
    "                            batch_size=batch_size) \n",
    "\n",
    "  val_loader = DataLoader(val_data,\n",
    "                            shuffle=False, \n",
    "                            batch_size=batch_size) \n",
    "\n",
    "  num_snapshot = 0\n",
    "  best_acc = 0\n",
    "\n",
    "  for epoch_ in range(epoch):\n",
    "    train_loss = train(train_loader, salt)\n",
    "    val_loss, accuracy = test(val_loader, salt)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "      best_acc = accuracy\n",
    "      best_param = salt.state_dict()\n",
    "\n",
    "    if (epoch_ + 1) % scheduler_step == 0:\n",
    "      torch.save(best_param, save_weight + weight_name + str(idx) + str(num_snapshot) + '.pth')\n",
    "      optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      num_snapshot += 1\n",
    "      best_acc = 0\n",
    "\n",
    "    print('epoch: {} train_loss: {:.3f} val_loss: {:.3f} val_accuracy: {:.3f}'.format(epoch_ + 1, train_loss, val_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgQ8uhBTr6Ts"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "bFhhsn5pxbkY",
    "outputId": "0e475b8b-93a2-4faa-be73-1322863612b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 18000/18000 [00:41<00:00, 434.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Snapshot 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:29<00:00, 33.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Snapshot 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:29<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Snapshot 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:29<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Snapshot 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:29<00:00, 33.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Snapshot 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:28<00:00, 34.67it/s]\n"
     ]
    }
   ],
   "source": [
    "test_id = [x[:-4] for x in os.listdir(test_image_dir) if x[-4:] == '.png']\n",
    "image_test = testImageFetch(test_id)\n",
    "overall_pred_101 = np.zeros((len(test_id), 101, 101), dtype=np.float32)\n",
    "\n",
    "for step in range(1, 6):\n",
    "\n",
    "  print('Predicting Snapshot', step)\n",
    "  pred_null = []\n",
    "\n",
    "  # Load weight\n",
    "  param = torch.load(save_weight + weight_name + '0' + str(step) + '.pth')\n",
    "  salt.load_state_dict(param)\n",
    "\n",
    "  # Dataloader\n",
    "  test_data = SaltDataset(image_test, mode='test', fine_size=fine_size, pad_left=pad_left, pad_right=pad_right)\n",
    "  test_loader = DataLoader(test_data,\n",
    "                            shuffle=False,\n",
    "                            batch_size=batch_size)\n",
    "  \n",
    "  # Prediction\n",
    "  salt.eval()\n",
    "  for images in tqdm(test_loader, total=len(test_loader)):\n",
    "    images = images.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      pred = salt(images)\n",
    "      pred = torch.sigmoid(pred).squeeze(1).cpu().numpy()\n",
    "      pred = pred[:, pad_left:pad_left + fine_size, pad_left:pad_left + fine_size]\n",
    "      pred_null.append(pred)\n",
    "  \n",
    "  idx = 0\n",
    "  for i in range(len(pred_null)):\n",
    "    for j in range(batch_size):\n",
    "      overall_pred_101[idx] += cv2.resize(pred_null[i][j], dsize=(101, 101))\n",
    "      idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkOT1GWjmdOC"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test_id, 'rle_mask':list(overall_pred_101)})\n",
    "submission['rle_mask'] = submission['rle_mask'].map(lambda x: rle_encode(x>5*0.5))\n",
    "submission.set_index('id', inplace=True)\n",
    "\n",
    "sample_submission = pd.read_csv('tgs-salt-identification-challenge/sample_submission.csv')\n",
    "sample_submission.set_index('id', inplace=True)\n",
    "submission = submission.reindex(sample_submission.index)\n",
    "submission.reset_index(inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Unet_Implementation_PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
